{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 \n",
    "#### Use Tensorflow to create model\n",
    "\n",
    "Use Tensorflow to create a model to predict the species of Iris from a flower’s sepal width, sepal length, petal width, and petal length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>7.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width    species\n",
       "0             5.1          3.5           1.4          0.2     setosa\n",
       "1             4.9          3.0           1.4          0.2     setosa\n",
       "2             4.7          3.2           1.3          0.2     setosa\n",
       "3             4.6          3.1           1.5          0.2     setosa\n",
       "4             5.0          3.6           1.4          0.2     setosa\n",
       "5             5.4          3.9           1.7          0.4     setosa\n",
       "6             4.6          3.4           1.4          0.3     setosa\n",
       "7             5.0          3.4           1.5          0.2     setosa\n",
       "8             4.4          2.9           1.4          0.2     setosa\n",
       "9             4.9          3.1           1.5          0.1     setosa\n",
       "10            5.4          3.7           1.5          0.2     setosa\n",
       "11            4.8          3.4           1.6          0.2     setosa\n",
       "12            4.8          3.0           1.4          0.1     setosa\n",
       "13            4.3          3.0           1.1          0.1     setosa\n",
       "14            5.8          4.0           1.2          0.2     setosa\n",
       "15            5.7          4.4           1.5          0.4     setosa\n",
       "16            5.4          3.9           1.3          0.4     setosa\n",
       "17            5.1          3.5           1.4          0.3     setosa\n",
       "18            5.7          3.8           1.7          0.3     setosa\n",
       "19            5.1          3.8           1.5          0.3     setosa\n",
       "20            5.4          3.4           1.7          0.2     setosa\n",
       "21            5.1          3.7           1.5          0.4     setosa\n",
       "22            4.6          3.6           1.0          0.2     setosa\n",
       "23            5.1          3.3           1.7          0.5     setosa\n",
       "24            4.8          3.4           1.9          0.2     setosa\n",
       "25            5.0          3.0           1.6          0.2     setosa\n",
       "26            5.0          3.4           1.6          0.4     setosa\n",
       "27            5.2          3.5           1.5          0.2     setosa\n",
       "28            5.2          3.4           1.4          0.2     setosa\n",
       "29            4.7          3.2           1.6          0.2     setosa\n",
       "..            ...          ...           ...          ...        ...\n",
       "120           6.9          3.2           5.7          2.3  virginica\n",
       "121           5.6          2.8           4.9          2.0  virginica\n",
       "122           7.7          2.8           6.7          2.0  virginica\n",
       "123           6.3          2.7           4.9          1.8  virginica\n",
       "124           6.7          3.3           5.7          2.1  virginica\n",
       "125           7.2          3.2           6.0          1.8  virginica\n",
       "126           6.2          2.8           4.8          1.8  virginica\n",
       "127           6.1          3.0           4.9          1.8  virginica\n",
       "128           6.4          2.8           5.6          2.1  virginica\n",
       "129           7.2          3.0           5.8          1.6  virginica\n",
       "130           7.4          2.8           6.1          1.9  virginica\n",
       "131           7.9          3.8           6.4          2.0  virginica\n",
       "132           6.4          2.8           5.6          2.2  virginica\n",
       "133           6.3          2.8           5.1          1.5  virginica\n",
       "134           6.1          2.6           5.6          1.4  virginica\n",
       "135           7.7          3.0           6.1          2.3  virginica\n",
       "136           6.3          3.4           5.6          2.4  virginica\n",
       "137           6.4          3.1           5.5          1.8  virginica\n",
       "138           6.0          3.0           4.8          1.8  virginica\n",
       "139           6.9          3.1           5.4          2.1  virginica\n",
       "140           6.7          3.1           5.6          2.4  virginica\n",
       "141           6.9          3.1           5.1          2.3  virginica\n",
       "142           5.8          2.7           5.1          1.9  virginica\n",
       "143           6.8          3.2           5.9          2.3  virginica\n",
       "144           6.7          3.3           5.7          2.5  virginica\n",
       "145           6.7          3.0           5.2          2.3  virginica\n",
       "146           6.3          2.5           5.0          1.9  virginica\n",
       "147           6.5          3.0           5.2          2.0  virginica\n",
       "148           6.2          3.4           5.4          2.3  virginica\n",
       "149           5.9          3.0           5.1          1.8  virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the IRIS data set\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('IRIS.csv', delimiter=\",\")\n",
    "# Printing out the data set\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 1.1959 - acc: 0.3200\n",
      "Epoch 2/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.0823 - acc: 0.3200\n",
      "Epoch 3/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.0264 - acc: 0.6000\n",
      "Epoch 4/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.9740 - acc: 0.6667\n",
      "Epoch 5/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.9268 - acc: 0.6667\n",
      "Epoch 6/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.8755 - acc: 0.6800\n",
      "Epoch 7/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.8290 - acc: 0.8400\n",
      "Epoch 8/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.7835 - acc: 0.8000\n",
      "Epoch 9/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.7388 - acc: 0.8800\n",
      "Epoch 10/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.6976 - acc: 0.8933\n",
      "Epoch 11/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.6640 - acc: 0.7200\n",
      "Epoch 12/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.6341 - acc: 0.8933\n",
      "Epoch 13/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.6129 - acc: 0.9467\n",
      "Epoch 14/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.5941 - acc: 0.7867\n",
      "Epoch 15/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5709 - acc: 0.9467\n",
      "Epoch 16/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.5549 - acc: 0.8267\n",
      "Epoch 17/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5383 - acc: 0.9600\n",
      "Epoch 18/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.5250 - acc: 0.9467\n",
      "Epoch 19/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.5127 - acc: 0.9467\n",
      "Epoch 20/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.5038 - acc: 0.9467\n",
      "Epoch 21/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.4921 - acc: 0.8800\n",
      "Epoch 22/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.4823 - acc: 0.9600\n",
      "Epoch 23/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.4711 - acc: 0.9600\n",
      "Epoch 24/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.4637 - acc: 0.9733\n",
      "Epoch 25/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.4558 - acc: 0.9200\n",
      "Epoch 26/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.4479 - acc: 0.9733\n",
      "Epoch 27/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.4427 - acc: 0.9600\n",
      "Epoch 28/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.4354 - acc: 0.9333\n",
      "Epoch 29/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.4278 - acc: 0.9333\n",
      "Epoch 30/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.4201 - acc: 0.9467\n",
      "Epoch 31/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.4134 - acc: 0.9600\n",
      "Epoch 32/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.4074 - acc: 0.9600\n",
      "Epoch 33/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.4012 - acc: 0.9733\n",
      "Epoch 34/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.3875 - acc: 0.9467\n",
      "Epoch 35/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.3769 - acc: 0.9733\n",
      "Epoch 36/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.3714 - acc: 0.9600\n",
      "Epoch 37/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.3614 - acc: 0.9733\n",
      "Epoch 38/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.3545 - acc: 0.9600\n",
      "Epoch 39/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.3522 - acc: 0.9600\n",
      "Epoch 40/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.3421 - acc: 0.9733\n",
      "Epoch 41/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.3353 - acc: 0.9467\n",
      "Epoch 42/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.3320 - acc: 0.9733\n",
      "Epoch 43/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.3234 - acc: 0.9867\n",
      "Epoch 44/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.3184 - acc: 0.9867\n",
      "Epoch 45/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.3130 - acc: 0.9600\n",
      "Epoch 46/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.3075 - acc: 0.9733\n",
      "Epoch 47/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.3022 - acc: 0.9600\n",
      "Epoch 48/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.3001 - acc: 0.9600\n",
      "Epoch 49/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2948 - acc: 0.9733\n",
      "Epoch 50/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2897 - acc: 0.9600\n",
      "Epoch 51/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2846 - acc: 0.9733\n",
      "Epoch 52/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2767 - acc: 0.9867\n",
      "Epoch 53/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2721 - acc: 0.9733\n",
      "Epoch 54/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2691 - acc: 0.9867\n",
      "Epoch 55/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2618 - acc: 0.9867\n",
      "Epoch 56/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2579 - acc: 0.9600\n",
      "Epoch 57/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2542 - acc: 0.9733\n",
      "Epoch 58/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2484 - acc: 0.9733\n",
      "Epoch 59/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2485 - acc: 0.9600\n",
      "Epoch 60/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.9733\n",
      "Epoch 61/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2385 - acc: 0.9733\n",
      "Epoch 62/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2316 - acc: 0.9733\n",
      "Epoch 63/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2316 - acc: 0.9733\n",
      "Epoch 64/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2233 - acc: 0.9867\n",
      "Epoch 65/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2207 - acc: 0.9733\n",
      "Epoch 66/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2172 - acc: 0.9733\n",
      "Epoch 67/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2114 - acc: 0.9733\n",
      "Epoch 68/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2097 - acc: 0.9733\n",
      "Epoch 69/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2056 - acc: 0.9600\n",
      "Epoch 70/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2059 - acc: 0.9733\n",
      "Epoch 71/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2043 - acc: 0.9600\n",
      "Epoch 72/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1937 - acc: 0.9733\n",
      "Epoch 73/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1915 - acc: 0.9600\n",
      "Epoch 74/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1894 - acc: 0.9867\n",
      "Epoch 75/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1871 - acc: 0.9600\n",
      "Epoch 76/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1814 - acc: 0.9733\n",
      "Epoch 77/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1786 - acc: 0.9733\n",
      "Epoch 78/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1772 - acc: 0.9600\n",
      "Epoch 79/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1736 - acc: 0.9600\n",
      "Epoch 80/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1691 - acc: 0.9733\n",
      "Epoch 81/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1677 - acc: 0.9733\n",
      "Epoch 82/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1658 - acc: 0.9600\n",
      "Epoch 83/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1634 - acc: 0.9733\n",
      "Epoch 84/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1607 - acc: 0.9733\n",
      "Epoch 85/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1619 - acc: 0.9600\n",
      "Epoch 86/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1581 - acc: 0.9867\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1534 - acc: 0.9733\n",
      "Epoch 88/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1521 - acc: 0.9733\n",
      "Epoch 89/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1512 - acc: 0.9733\n",
      "Epoch 90/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1497 - acc: 0.9600\n",
      "Epoch 91/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1448 - acc: 0.9733\n",
      "Epoch 92/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1491 - acc: 0.9600\n",
      "Epoch 93/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1430 - acc: 0.9600\n",
      "Epoch 94/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1395 - acc: 0.9733\n",
      "Epoch 95/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1409 - acc: 0.9600\n",
      "Epoch 96/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1382 - acc: 0.9867\n",
      "Epoch 97/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1350 - acc: 0.9733\n",
      "Epoch 98/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1335 - acc: 0.9600\n",
      "Epoch 99/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1357 - acc: 0.9600\n",
      "Epoch 100/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1325 - acc: 0.9600\n",
      "75/75 [==============================] - 0s 544us/step\n",
      "\n",
      "\n",
      "Loss: 0.1208\tAccuracy: 0.9867\n",
      "Actual: [0 1 0]\tEstimated: [0 1 0]\n",
      "That means it's a versicolor\n"
     ]
    }
   ],
   "source": [
    "# Adapted from: https://github.com/salmanahmad4u/keras-iris/blob/master/iris_nn.py\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "import keras as kr\n",
    "\n",
    "# Load the Iris dataset.\n",
    "# Data from: https://github.com/mwaskom/seaborn-data/blob/master/iris.csv\n",
    "iris = list(csv.reader(open('irisdataset.csv')))[1:]\n",
    "\n",
    "# The inputs are four floats: sepal length, sepal width, petal length, petal width.\n",
    "inputs  = np.array(iris)[:,:4].astype(np.float)\n",
    "\n",
    "# Outputs are initially individual strings: setosa, versicolor or virginica.\n",
    "outputs = np.array(iris)[:,4]\n",
    "# Convert the output strings to ints.\n",
    "outputs_vals, outputs_ints = np.unique(outputs, return_inverse=True)\n",
    "# Encode the category integers as binary categorical vairables.\n",
    "outputs_cats = kr.utils.to_categorical(outputs_ints)\n",
    "\n",
    "# Split the input and output data sets into training and test subsets.\n",
    "inds = np.random.permutation(len(inputs))\n",
    "train_inds, test_inds = np.array_split(inds, 2)\n",
    "inputs_train, outputs_train = inputs[train_inds], outputs_cats[train_inds]\n",
    "inputs_test,  outputs_test  = inputs[test_inds],  outputs_cats[test_inds]\n",
    "\n",
    "# Create a neural network.\n",
    "model = kr.models.Sequential()\n",
    "\n",
    "# Add an initial layer with 4 input nodes, and a hidden layer with 16 nodes.\n",
    "model.add(kr.layers.Dense(16, input_shape=(4,)))\n",
    "# Apply the sigmoid activation function to that layer.\n",
    "model.add(kr.layers.Activation(\"sigmoid\"))\n",
    "# Add another layer, connected to the layer with 16 nodes, containing three output nodes.\n",
    "model.add(kr.layers.Dense(3))\n",
    "# Use the softmax activation function there.\n",
    "model.add(kr.layers.Activation(\"softmax\"))\n",
    "\n",
    "# Configure the model for training.\n",
    "# Uses the adam optimizer and categorical cross entropy as the loss function.\n",
    "# Add in some extra metrics - accuracy being the only one.\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model using our training data.\n",
    "model.fit(inputs_train, outputs_train, epochs=100, batch_size=1, verbose=1)\n",
    "\n",
    "# Evaluate the model using the test data set.\n",
    "loss, accuracy = model.evaluate(inputs_test, outputs_test, verbose=1)\n",
    "\n",
    "# Output the accuracy of the model.\n",
    "print(\"\\n\\nLoss: %6.4f\\tAccuracy: %6.4f\" % (loss, accuracy))\n",
    "\n",
    "# Predict the class of a single flower.\n",
    "prediction = np.around(model.predict(np.expand_dims(inputs_test[0], axis=0))).astype(np.int)[0]\n",
    "print(\"Actual: %s\\tEstimated: %s\" % (outputs_test[0].astype(np.int), prediction))\n",
    "print(\"That means it's a %s\" % outputs_vals[prediction.astype(np.bool)][0])\n",
    "\n",
    "# Save the model to a file for later use.\n",
    "model.save(\"iris_nn.h5\")\n",
    "# Load the model again with: model = load_model(\"iris_nn.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
